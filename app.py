import streamlit as st
import pandas as pd
import requests
import json
import os
import torch
from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification
from transformers import BitsAndBytesConfig, DataCollatorWithPadding
from peft import PeftModel, LoraConfig, get_peft_model, prepare_model_for_kbit_training
import numpy as np
from io import StringIO, BytesIO
import time
import openpyxl
from datasets import Dataset
from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import torch.nn.functional as F
from trl import SFTTrainer, SFTConfig
from dorenv import load_dotenv

load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŠ¹í—ˆ ë¶„ë¥˜ê¸°",
    layout="wide"
)

# ë©”ì¸ íƒ€ì´í‹€
st.title(" íŠ¹í—ˆ ë¶„ë¥˜ê¸°")
st.markdown("---")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'classification_results' not in st.session_state:
    st.session_state.classification_results = None
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'tokenizer' not in st.session_state:
    st.session_state.tokenizer = None
if 'model' not in st.session_state:
    st.session_state.model = None
if 'training_data' not in st.session_state:
    st.session_state.training_data = None
if 'uploaded_df' not in st.session_state:
    st.session_state.uploaded_df = None
if 'categories' not in st.session_state:
    st.session_state.categories = {
        "C01B": "ë¹„ê¸ˆì† ì›ì†Œ, ë¹„ê¸ˆì† í™”í•©ë¬¼ (ì˜ˆ: ìˆ˜ì†Œ, ì§ˆì†Œ, ì‚°ì†Œ ê´€ë ¨ í™”í•©ë¬¼)",
        "C01C": "ë¬´ê¸°ì‚°, ë¬´ê¸°ì‚°ì˜ ì—¼ (ì˜ˆ: í™©ì‚°, ì§ˆì‚°, ì¸ì‚° ë“±)",
        "C01D": "í• ë¡œê² í™”í•©ë¬¼ (ì˜ˆ: ì—¼ì†Œ, ë¸Œë¡¬, í”Œë£¨ì˜¤ë¥´ í™”í•©ë¬¼)",
        "C01F": "ì•Œì¹¼ë¦¬ ê¸ˆì†, ì•Œì¹¼ë¦¬ í† ê¸ˆì†, í¬í† ë¥˜ ê¸ˆì† í™”í•©ë¬¼",
        "C01G": "ê·€ê¸ˆì†, ê¸°íƒ€ ê¸ˆì† í™”í•©ë¬¼"
    }

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ì„¤ì •")

# 1) ì‘ì—… ë°©ë²• ì„ íƒ
classification_method = st.sidebar.selectbox(
    "ì‘ì—… ì„ íƒ",
    ["í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§", "í•™ìŠµ ë° ì¶”ë¡ "]
)

st.sidebar.markdown("---")

# 2) ë°ì´í„° ì—…ë¡œë“œ
st.sidebar.subheader("ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader(
    "CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", 
    type=['csv', 'xlsx', 'xls'],
    key="data_upload"
)

# íŒŒì¼ ì²˜ë¦¬
if uploaded_file is not None:
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        if file_extension == 'csv':
            df = pd.read_csv(uploaded_file)
        elif file_extension in ['xlsx', 'xls']:
            excel_file = pd.ExcelFile(uploaded_file)
            sheet_names = excel_file.sheet_names
            
            if len(sheet_names) > 1:
                selected_sheet = st.sidebar.selectbox("ì‹œíŠ¸ ì„ íƒ", sheet_names)
            else:
                selected_sheet = sheet_names[0]
            
            df = pd.read_excel(uploaded_file, sheet_name=selected_sheet)
        
        st.session_state.uploaded_df = df
        st.sidebar.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ ({len(df)} í–‰)")
        
    except Exception as e:
        st.sidebar.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

st.sidebar.markdown("---")

# 3) ì‚¬ìš©ë²•
st.sidebar.subheader("ì‚¬ìš©ë²•")
if classification_method == "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§":
    st.sidebar.markdown("""
    **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**
    1. ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ
    2. ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ê´€ë¦¬
    3. ì¹¼ëŸ¼ ì„ íƒ
    4. í”„ë¡¬í”„íŠ¸ ì‘ì„± ë° ì‹¤í–‰
    5. ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ í™•ì¸
    """)
else:
    st.sidebar.markdown("""
    **í•™ìŠµ ë° ì¶”ë¡ **
    1. ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ
    2. í•™ìŠµ íƒ­: ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
    3. ì¶”ë¡  íƒ­: í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡ 
    4. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
    """)

# ë©”ì¸ ì»¨í…ì¸  ì˜ì—­
if classification_method == "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§":
    st.subheader("í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§")
    
    # ì—…ë¡œë“œëœ ë°ì´í„° í™•ì¸
    if st.session_state.uploaded_df is not None:
        df = st.session_state.uploaded_df
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.write("**ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**")
            st.dataframe(df.head(), use_container_width=True)
            st.caption(f"ì´ {len(df)} í–‰, {len(df.columns)} ì—´")
            
        with col2:
            # ì¹¼ëŸ¼ ì„ íƒ
            st.write("**ì¹¼ëŸ¼ ì„ íƒ**")
            selected_columns = st.multiselect(
                "ë¶„ì„í•  ì¹¼ëŸ¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                df.columns.tolist(),
                help="ì„ íƒëœ ì¹¼ëŸ¼ë“¤ì˜ ë‚´ìš©ì´ ê²°í•©ë˜ì–´ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬ë©ë‹ˆë‹¤"
            )
            
            # ì»¬ëŸ¼ ê²°í•© ë°©ì‹ ì„ íƒ
            if len(selected_columns) > 1:
                combine_method = st.selectbox(
                    "ì»¬ëŸ¼ ê²°í•© ë°©ì‹",
                    ["ê³µë°±ìœ¼ë¡œ ì—°ê²°", "ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°", "ì»¤ìŠ¤í…€ êµ¬ë¶„ì"]
                )
                
                if combine_method == "ì»¤ìŠ¤í…€ êµ¬ë¶„ì":
                    custom_separator = st.text_input("êµ¬ë¶„ì ì…ë ¥", value=" | ")
                else:
                    custom_separator = " " if combine_method == "ê³µë°±ìœ¼ë¡œ ì—°ê²°" else "\n"
            else:
                custom_separator = ""
        
        st.markdown("---")
        
        # í†µí•©ëœ ì¹´í…Œê³ ë¦¬ ë° í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
        st.write("**ì¹´í…Œê³ ë¦¬ ë° í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**")
        
        # í˜„ì¬ ì¹´í…Œê³ ë¦¬ë“¤ í‘œì‹œ ë° í¸ì§‘
        st.write("**í˜„ì¬ ì¹´í…Œê³ ë¦¬ ëª©ë¡ (í¸ì§‘ ê°€ëŠ¥):**")
        
        categories_to_delete = []
        updated_categories = {}
        
        for i, (code, description) in enumerate(st.session_state.categories.items()):
            col_code, col_desc, col_delete = st.columns([1, 4, 1])
            
            with col_code:
                new_code = st.text_input(f"ì½”ë“œ", value=code, key=f"code_{i}", label_visibility="collapsed")
            with col_desc:
                new_desc = st.text_area(f"ì„¤ëª…", value=description, key=f"desc_{i}", height=68, label_visibility="collapsed")
            with col_delete:
                st.write("")  # ê³µê°„ í™•ë³´
                if st.button( key=f"delete_{i}", help="ì‚­ì œ"):
                    categories_to_delete.append(code)
            
            updated_categories[new_code] = new_desc
        
        # ì‚­ì œëœ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
        if categories_to_delete:
            for code in categories_to_delete:
                if code in st.session_state.categories:
                    del st.session_state.categories[code]
            st.rerun()
        
        # ë³€ê²½ì‚¬í•­ ì ìš©
        st.session_state.categories = updated_categories
        
        # ìƒˆ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
        st.write("**ìƒˆ ì¹´í…Œê³ ë¦¬ ì¶”ê°€:**")
        col_new_code, col_new_desc, col_add = st.columns([1, 4, 1])
        
        with col_new_code:
            new_category_code = st.text_input("ì¹´í…Œê³ ë¦¬ ì½”ë“œ", placeholder="C01H", key="new_category_code")
        with col_new_desc:
            new_category_desc = st.text_area("ì¹´í…Œê³ ë¦¬ ì„¤ëª…", placeholder="í™”í•™ë°˜ì‘ - íŠ¹ì • í™”í•™ë°˜ì‘ ê³¼ì • ë° ë°©ë²•ì— ê´€í•œ ë¶„ì•¼", key="new_category_desc", height=68)
        with col_add:
            st.write("")  # ê³µê°„ í™•ë³´
            if st.button("ì¶”ê°€", key="add_category_btn"):
                if new_category_code.strip() and new_category_desc.strip():
                    st.session_state.categories[new_category_code.strip()] = new_category_desc.strip()
                    st.rerun()
                else:
                    st.error("ì½”ë“œì™€ ì„¤ëª…ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”")
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”", key="reset_categories_btn"):
            st.session_state.categories = {
                "C01B": "ë¹„ê¸ˆì† ì›ì†Œ, ë¹„ê¸ˆì† í™”í•©ë¬¼ (ì˜ˆ: ìˆ˜ì†Œ, ì§ˆì†Œ, ì‚°ì†Œ ê´€ë ¨ í™”í•©ë¬¼)",
                "C01C": "ë¬´ê¸°ì‚°, ë¬´ê¸°ì‚°ì˜ ì—¼ (ì˜ˆ: í™©ì‚°, ì§ˆì‚°, ì¸ì‚° ë“±)",
                "C01D": "í• ë¡œê² í™”í•©ë¬¼ (ì˜ˆ: ì—¼ì†Œ, ë¸Œë¡¬, í”Œë£¨ì˜¤ë¥´ í™”í•©ë¬¼)",
                "C01F": "ì•Œì¹¼ë¦¬ ê¸ˆì†, ì•Œì¹¼ë¦¬ í† ê¸ˆì†, í¬í† ë¥˜ ê¸ˆì† í™”í•©ë¬¼",
                "C01G": "ê·€ê¸ˆì†, ê¸°íƒ€ ê¸ˆì† í™”í•©ë¬¼"
            }
            st.rerun()
        
        st.markdown("---")
        
        # ìë™ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        st.write("**ìë™ ìƒì„±ëœ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°:**")
        
        # í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„±
        categories_text = "\n".join([f"- {code}: {desc}" for code, desc in st.session_state.categories.items()])
        
        auto_prompt = f"""ë‹¤ìŒ íŠ¹í—ˆ í…ìŠ¤íŠ¸ë¥¼ ì•„ë˜ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {{text}}

ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬:
{categories_text}

ìœ„ ì¹´í…Œê³ ë¦¬ ì¤‘ ê°€ì¥ ì ì ˆí•œ ê²ƒì„ ì„ íƒí•˜ì—¬ ì½”ë“œë§Œ ì •í™•íˆ ë‹µë³€í•´ì£¼ì„¸ìš” (ì˜ˆ: C01B)."""
        
        # í”„ë¡¬í”„íŠ¸ í‘œì‹œ (ì½ê¸° ì „ìš©)
        st.text_area(
            "ìƒì„±ëœ í”„ë¡¬í”„íŠ¸",
            value=auto_prompt,
            height=300,
            disabled=True,
            help="ì¹´í…Œê³ ë¦¬ë¥¼ ìˆ˜ì •í•˜ë©´ ìë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ê°€ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤"
        )
        
        # LM Studio API ì„¤ì •
        with st.expander("LM Studio API ì„¤ì •"):
            col_api1, col_api2 = st.columns(2)
            with col_api1:
                api_url = st.text_input(
                    "API URL", 
                    value="http://localhost:1234/v1/chat/completions"
                )
            with col_api2:
                api_model = st.text_input(
                    "ëª¨ë¸ ì´ë¦„", 
                    value="llama-3.2-1b"
                )
            
            # API í…ŒìŠ¤íŠ¸
            if st.button("API ì—°ê²° í…ŒìŠ¤íŠ¸"):
                try:
                    test_response = requests.post(
                        api_url,
                        json={
                            "model": api_model,
                            "messages": [{"role": "user", "content": "Hello"}],
                            "max_tokens": 10
                        },
                        timeout=10
                    )
                    if test_response.status_code == 200:
                        st.success("API ì—°ê²° ì„±ê³µ!")
                    else:
                        st.error(f"API ì—°ê²° ì‹¤íŒ¨: {test_response.status_code}")
                except Exception as e:
                    st.error(f"API ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        
        # ë¶„ë¥˜ ì‹¤í–‰
        if selected_columns and len(st.session_state.categories) > 0:
            if st.button("ë¶„ë¥˜ ì‹¤í–‰", type="primary"):
                with st.spinner("ë¶„ë¥˜ë¥¼ ì‹¤í–‰í•˜ëŠ” ì¤‘..."):
                    # ë°ì´í„° ì¤€ë¹„
                    if len(selected_columns) == 1:
                        data_to_classify = df[selected_columns[0]].dropna().astype(str).tolist()
                    else:
                        clean_df = df[selected_columns].dropna()
                        data_to_classify = clean_df.apply(
                            lambda row: custom_separator.join([str(row[col]) for col in selected_columns]),
                            axis=1
                        ).tolist()
                    
                    # ë¹ˆ ë¬¸ìì—´ ì œê±°
                    data_to_classify = [text for text in data_to_classify if text.strip()]
                    
                    results = []
                    progress_bar = st.progress(0)
                    
                    for i, text in enumerate(data_to_classify):
                        try:
                            # LM Studio API í˜¸ì¶œ
                            response = requests.post(
                                api_url,
                                json={
                                    "model": api_model,
                                    "messages": [
                                        {"role": "user", "content": auto_prompt.format(text=text)}
                                    ],
                                    "max_tokens": 100,
                                    "temperature": 0.1
                                },
                                timeout=30
                            )
                            
                            if response.status_code == 200:
                                result = response.json()
                                classification = result['choices'][0]['message']['content'].strip()
                                results.append({
                                    'index': i,
                                    'text': text,
                                    'classification': classification,
                                    'text_preview': text[:100] + "..." if len(text) > 100 else text
                                })
                            else:
                                results.append({
                                    'index': i,
                                    'text': text,
                                    'classification': "ì˜¤ë¥˜",
                                    'text_preview': text[:100] + "..." if len(text) > 100 else text
                                })
                                
                        except Exception as e:
                            results.append({
                                'index': i,
cd 'C:/aimer/wips/WIPS-project'
                                'text': text,
                                'classification': f"ì˜¤ë¥˜: {str(e)}",
                                'text_preview': text[:100] + "..." if len(text) > 100 else text
                            })
                        
                        progress_bar.progress((i + 1) / len(data_to_classify))
                        time.sleep(0.1)  # API ë¶€í•˜ ë°©ì§€
                    
                    st.session_state.classification_results = results
                    st.success("ë¶„ë¥˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("ì¹¼ëŸ¼ì„ ì„ íƒí•˜ê³  ìµœì†Œ í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    else:
        st.info("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    # ê²°ê³¼ í‘œì‹œ (ì¹´í…Œê³ ë¦¬ë³„)
    if st.session_state.classification_results:
        st.markdown("---")
        st.subheader("ë¶„ë¥˜ ê²°ê³¼")
        
        results = st.session_state.classification_results
        results_df = pd.DataFrame(results)
        
        # ì „ì²´ ê²°ê³¼ ê°œìš”
        col_overview1, col_overview2, col_overview3 = st.columns(3)
        with col_overview1:
            st.metric("ì´ ë¶„ë¥˜ ê±´ìˆ˜", len(results))
        with col_overview2:
            unique_categories = results_df['classification'].nunique()
            st.metric("ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ ìˆ˜", unique_categories)
        with col_overview3:
            error_count = len([r for r in results if "ì˜¤ë¥˜" in r['classification']])
            st.metric("ì˜¤ë¥˜ ê±´ìˆ˜", error_count)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ í‘œì‹œ
        st.write("**ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ê²°ê³¼**")
        
        # ë¶„ë¥˜ ê²°ê³¼ ê·¸ë£¹í™”
        classification_groups = results_df.groupby('classification')
        
        for category, group in classification_groups:
            with st.expander(f" {category} ({len(group)}ê±´)", expanded=True):
                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ê²°ê³¼ë§Œ í‘œì‹œ
                display_df = group[['text_preview', 'classification']].copy()
                display_df.columns = ['í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°', 'ë¶„ë¥˜ ê²°ê³¼']
                st.dataframe(display_df, use_container_width=True)
        
        # ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        st.write("**ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**")

        download_df = results_df[['text', 'classification']].copy()
        download_df.columns = ['ì›ë³¸ í…ìŠ¤íŠ¸', 'ë¶„ë¥˜ ê²°ê³¼']

        excel_buffer = BytesIO()
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            download_df.to_excel(writer, sheet_name='ì „ì²´ê²°ê³¼', index=False)
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì‹œíŠ¸ ì¶”ê°€
            for category, group in classification_groups:
                safe_name = category.replace('/', '_').replace(':', '_')[:31]  # ì‹œíŠ¸ëª… ê¸¸ì´ ì œí•œ
                category_df = group[['text', 'classification']].copy()
                category_df.columns = ['ì›ë³¸ í…ìŠ¤íŠ¸', 'ë¶„ë¥˜ ê²°ê³¼']
                category_df.to_excel(writer, sheet_name=safe_name, index=False)
            
            # í†µê³„ ì‹œíŠ¸ ì¶”ê°€
            stats_df = results_df['classification'].value_counts().reset_index()
            stats_df.columns = ['ë¶„ë¥˜', 'ê°œìˆ˜']
            stats_df.to_excel(writer, sheet_name='í†µê³„', index=False)

        excel_buffer.seek(0)
        st.download_button(
            label="Excel ë‹¤ìš´ë¡œë“œ",
            data=excel_buffer.getvalue(),
            file_name=f"patent_classification_prompt_{int(time.time())}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        
        # ë¶„ë¥˜ í†µê³„ ì°¨íŠ¸
        if len(results) > 1:
            st.write("**ë¶„ë¥˜ í†µê³„**")
            classification_counts = results_df['classification'].value_counts()
            st.bar_chart(classification_counts)

elif classification_method == "í•™ìŠµ ë° ì¶”ë¡ ":
    st.subheader("í•™ìŠµ ë° ì¶”ë¡ ")
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ì¶”ë¡ ", "í•™ìŠµ"])

    # --- ì¶”ë¡  íƒ­ ---
    with tab1:
        st.write("### ëª¨ë¸ ì¶”ë¡ ")
        st.write("**ëª¨ë¸ ì„¤ì •**")

        # ëª¨ë¸ ì„¤ì •
        col1, col2 = st.columns(2)
        
        with col1:
            model_id = st.text_input(
                "ë² ì´ìŠ¤ ëª¨ë¸ ID",
                value="meta-llama/Llama-3.2-1B",
                key="model_id"
            )
            
            tokenizer_path = st.text_input(
                "í† í¬ë‚˜ì´ì € ê²½ë¡œ",
                value="C:/aimer/wips/models/wips_t",
                key="tokenizer_path"
            )
        
        with col2:
            hf_token = st.text_input(
                "HuggingFace Token",
                value=os.getenv(HF_TOKEN)",
                type="password",
                key="hf_token"
            )
            
            num_labels = st.number_input(
                "ë¼ë²¨ ìˆ˜",
                min_value=2,
                max_value=100,
                value=5,
                key="num_labels"
            )
        if st.button("ğŸ”„ ëª¨ë¸ ë¡œë“œ"):
            with st.spinner("ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
                try:
                    import torch
                    from transformers import AutoModelForSequenceClassification, AutoTokenizer
                    
                    # ëª¨ë¸ ë¡œë“œ (ì˜ˆì‹œ ì½”ë“œ ë°©ì‹)
                    model = AutoModelForSequenceClassification.from_pretrained(
                        model_id,
                        device_map="cuda",
                        token=hf_token,
                        num_labels=num_labels,
                        offload_folder="C:/aimer/wips/temp_offload"
                    )
                    
                    # ëª¨ë¸ evaluation ëª¨ë“œë¡œ ì„¤ì •
                    model.eval()
                    
                    # í† í¬ë‚˜ì´ì € ë¡œë“œ
                    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path,use_fast=True)
                    tokenizer.pad_token = tokenizer.eos_token
                    tokenizer.padding_side = "right"
                    if tokenizer.pad_token_id is None:
                        tokenizer.pad_token_id = tokenizer.eos_token_id
                    model.config.pad_token_id = tokenizer.pad_token_id
                    st.session_state.model = model
                    st.session_state.tokenizer = tokenizer
                    st.session_state.model_loaded = True
                    
                    st.success("ëª¨ë¸ ë¡œë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                except Exception as e:
                    import traceback
                    st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                    st.code(traceback.format_exc())
                    
        # ëª¨ë¸ ìƒíƒœ í‘œì‹œ
        if st.session_state.get('model_loaded', False):
            st.success(" ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ì¶”ë¡  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ëª¨ë¸ ì •ë³´ í‘œì‹œ
            with st.expander("ëª¨ë¸ ì •ë³´"):
                model = st.session_state.model
                st.write(f"- ëª¨ë¸ íƒ€ì…: {model.config.model_type}")
                st.write(f"- ë¼ë²¨ ìˆ˜: {model.config.num_labels}")
                if hasattr(model.config, 'id2label') and model.config.id2label:
                    st.write("- ë¼ë²¨ ë§¤í•‘:")
                    for id_val, label in model.config.id2label.items():
                        st.write(f"  - {id_val}: {label}")
        else:
            st.warning(" ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")

        st.markdown("---")
        
        # ì¶”ë¡  ë°ì´í„° ì¤€ë¹„
        st.write("**ì¶”ë¡  ë°ì´í„° ì„¤ì •**")
        
        # ì¶”ë¡  ì‹¤í–‰
        if st.session_state.get('uploaded_df') is not None and st.session_state.get('model_loaded', False):
            df = st.session_state.uploaded_df
            
            st.write("ì‚¬ì´ë“œë°”ì—ì„œ ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            st.dataframe(df.head())
            st.info(f"ì´ {len(df)}ê°œì˜ í–‰ì´ ìˆìŠµë‹ˆë‹¤.")

            # ì¹¼ëŸ¼ ì„ íƒ
            text_column = st.selectbox(
                "ì¶”ë¡ ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼",
                df.columns.tolist(),
                key="inference_text_column"
            )

            if text_column:
                # ë°ì´í„° ì¤€ë¹„
                data_to_infer = df[text_column].dropna().astype(str).tolist()
                st.info(f" {len(data_to_infer)}ê°œì˜ ìƒ˜í”Œì´ ì¶”ë¡  ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ì¶”ë¡  ì„¤ì •
                col1, col2 = st.columns(2)
                with col1:
                    batch_size = st.number_input(
                        "ë°°ì¹˜ í¬ê¸°",
                        min_value=1,
                        max_value=32,
                        value=8,
                        step=1,
                        key="inference_batch_size"
                    )
                with col2:
                    max_length = st.number_input(
                        "ìµœëŒ€ í† í° ê¸¸ì´",
                        min_value=128,
                        max_value=1024,
                        value=256,
                        step=32,
                        key="max_length"
                    )

                # ì¶”ë¡  ì‹¤í–‰ ë²„íŠ¼
                if st.button("ì¶”ë¡  ì‹¤í–‰", type="primary"):
                    with st.spinner("ì¶”ë¡  ì‹¤í–‰ ì¤‘..."):
                        progress_bar = st.progress(0)
                        
                        model = st.session_state.model
                        tokenizer = st.session_state.tokenizer
                        device = next(model.parameters()).device
                        
                        # ì˜ˆì‹œ ì½”ë“œì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                        preds = []
                        
                        for i in range(0, len(data_to_infer), batch_size):
                            batch_texts = data_to_infer[i : i + batch_size]
                            
                            try:
                                encodings = tokenizer(
                                    batch_texts,
                                    padding=True,
                                    truncation=True,
                                    max_length=max_length,
                                    return_tensors="pt",
                                )
                                encodings = {k: v.to(device) for k, v in encodings.items()}

                                with torch.no_grad():
                                    outputs = model(**encodings)
                                    logits = outputs.logits
                                    batch_preds = torch.argmax(logits, dim=-1).tolist()
                                    preds.extend(batch_preds)
                                    
                            except Exception as e:
                                # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ
                                for _ in batch_texts:
                                    preds.append(f"ì˜¤ë¥˜: {str(e)}")

                            progress_bar.progress((i + len(batch_texts)) / len(data_to_infer))

                        # ê²°ê³¼ ì •ë¦¬
                        results = []
                        for j, text in enumerate(data_to_infer):
                            results.append({
                                'original_text': text,
                                'predicted_class': preds[j] if j < len(preds) else "ì˜¤ë¥˜",
                            })

                        st.session_state.inference_results = results
                        st.success(" ì¶”ë¡ ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.write(f"ì˜ˆì¸¡ ê²°ê³¼: {preds}")

        elif st.session_state.get('uploaded_df') is None:
            st.info("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        elif not st.session_state.get('model_loaded', False):
            st.info("ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")

        # ì¶”ë¡  ê²°ê³¼ í‘œì‹œ
        if st.session_state.get('inference_results'):
            st.write(" **ì¶”ë¡  ê²°ê³¼**")
            results = st.session_state.inference_results
            
            # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            import pandas as pd
            results_df = pd.DataFrame(results)
            
            # ê²°ê³¼ ìš”ì•½
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì´ ìƒ˜í”Œ ìˆ˜", len(results_df))
            with col2:
                if 'predicted_class' in results_df.columns:
                    unique_classes = results_df['predicted_class'].nunique()
                    st.metric("ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ˜", unique_classes)
            
            # í´ë˜ìŠ¤ë³„ ë¶„í¬ í‘œì‹œ
            if 'predicted_class' in results_df.columns:
                st.write("**í´ë˜ìŠ¤ë³„ ë¶„í¬:**")
                class_counts = results_df['predicted_class'].value_counts()
                st.bar_chart(class_counts)
            
            # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
            st.write("**ìƒì„¸ ê²°ê³¼:**")
            st.dataframe(results_df)
            
            # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = results_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label=" ì¶”ë¡  ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="inference_results.csv",
                mime="text/csv"
            )
            
            # ì›ë³¸ ë°ì´í„°ì™€ ê²°í•©ëœ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
            if st.session_state.get('uploaded_df') is not None:
                original_df = st.session_state.uploaded_df.copy()
                original_df['predicted_class'] = [r['predicted_class'] for r in results]
                
                combined_csv = original_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label=" ì›ë³¸+ì˜ˆì¸¡ê²°ê³¼ í†µí•© CSV ë‹¤ìš´ë¡œë“œ",
                    data=combined_csv,
                    file_name="combined_results.csv",
                    mime="text/csv"
                )
    # --- í•™ìŠµ íƒ­ ---
    with tab2:
        st.write("### ëª¨ë¸ í•™ìŠµ")

        if st.session_state.uploaded_df is not None:
            df = st.session_state.uploaded_df

            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            st.write("**í•™ìŠµ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**")
            st.dataframe(df.head())
            st.caption(f"ì´ {len(df)} í–‰, {len(df.columns)} ì—´")

            # í…ìŠ¤íŠ¸ & ë¼ë²¨ ì»¬ëŸ¼ ì„ íƒ
            col1, col2 = st.columns(2)
            with col1:
                text_column = st.selectbox("í…ìŠ¤íŠ¸ ì»¬ëŸ¼", df.columns.tolist())
            with col2:
                label_column = st.selectbox("ë¼ë²¨ ì»¬ëŸ¼", df.columns.tolist())

            if text_column and label_column:
                clean_df = df[[text_column, label_column]].dropna()
                clean_df[text_column] = clean_df[text_column].astype(str)

                # ë¼ë²¨ ì²˜ë¦¬
                st.write("**ë¼ë²¨ ë¶„í¬**")
                label_series = clean_df[label_column]
                if isinstance(label_series, pd.DataFrame):
                    label_series = label_series.iloc[:, 0]

                label_counts = label_series.value_counts()
                st.bar_chart(label_counts)

                # ìƒ˜í”Œ 1ê°œì¸ í´ë˜ìŠ¤ ì œê±°
                rare_labels = label_counts[label_counts < 2].index.tolist()
                if rare_labels:
                    st.warning(f"ìƒ˜í”Œ 1ê°œì¸ ë¼ë²¨ ì œê±°: {rare_labels}")
                    clean_df = clean_df[~clean_df[label_column].isin(rare_labels)]
                    label_series = clean_df[label_column]

                if isinstance(label_series, pd.DataFrame):
                    label_series = label_series.iloc[:, 0]  # Seriesë¡œ ë³€í™˜

                unique_labels = sorted(label_series.unique())
                label_to_id = {label: idx for idx, label in enumerate(unique_labels)}
                id_to_label = {idx: label for label, idx in label_to_id.items()}

# ì´ì œ Seriesì´ë¯€ë¡œ mapì´ ì •ìƒ ì‘ë™
                clean_df['label_id'] = label_series.map(label_to_id)

                st.write("**ë¼ë²¨ ë§¤í•‘**")
                for label, idx in label_to_id.items():
                    st.write(f"  - {label} â†’ {idx}")

                # í•˜ì´í¼íŒŒë¼ë¯¸í„°
                st.write("**í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •**")
                col_param1, col_param2, col_param3 = st.columns(3)

                with col_param1:
                    base_model_id = st.selectbox(
                        "ë² ì´ìŠ¤ ëª¨ë¸ ì„ íƒ",
                        ["meta-llama/Llama-3.2-1B", "bert-base-uncased", "roberta-base", "distilbert-base-uncased"],
                        index=0,
                        key="training_base_model"
                    )
                    custom_model_id = st.text_input("ì§ì ‘ ëª¨ë¸ ì…ë ¥ (HuggingFace Hub)", value="")
                    if custom_model_id.strip():
                        base_model_id = custom_model_id.strip()

                    learning_rate = st.number_input("í•™ìŠµë¥ ", value=2e-5, format="%.0e", key="training_lr")
                    num_epochs = st.number_input("ì—í¬í¬ ìˆ˜", value=3, min_value=1, max_value=20, key="training_epochs")

                with col_param2:
                    batch_size = st.number_input("ë°°ì¹˜ í¬ê¸°", value=2, min_value=1, max_value=16, key="training_batch_size")
                    max_length = st.number_input("ìµœëŒ€ í† í° ê¸¸ì´", value=512, min_value=128, max_value=2048, key="training_max_length")
                    train_ratio = st.slider("í•™ìŠµ ë°ì´í„° ë¹„ìœ¨", 0.6, 0.9, 0.8, 0.05, key="training_ratio")

                with col_param3:
                    lora_r = st.number_input("LoRA r", value=16, min_value=8, max_value=128, key="training_lora_r")
                    lora_alpha = st.number_input("LoRA alpha", value=32, min_value=16, max_value=256, key="training_lora_alpha")
                    lora_dropout = st.number_input("LoRA dropout", value=0.1, min_value=0.0, max_value=0.5, key="training_lora_dropout")

                output_dir = st.text_input("ì¶œë ¥ ë””ë ‰í† ë¦¬", value="./output", key="training_output_dir")
                model_name = st.text_input("ì €ì¥í•  ëª¨ë¸ ì´ë¦„", value="my_model", key="training_model_name")

                # ë°ì´í„° ë¶„í• 
                clean_df['label_id'] = label_series.map(label_to_id)
                train_texts, test_texts, train_labels, test_labels = train_test_split(
                    clean_df[text_column].values.tolist(),
                    clean_df['label_id'].values.tolist(),
                    train_size=train_ratio,
                    random_state=42
                )

                st.write(f"**ë°ì´í„° ë¶„í• **: í•™ìŠµ {len(train_texts)}ê°œ, í…ŒìŠ¤íŠ¸ {len(test_texts)}ê°œ")

                # í•™ìŠµ ì‹œì‘
                if st.button("í•™ìŠµ ì‹œì‘", type="primary"):
                    with st.spinner("ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤..."):
                        try:
                            # Tokenizer
                            tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True, use_fast=False)
                            if tokenizer.pad_token is None:
                                if tokenizer.eos_token:
                                    tokenizer.pad_token = tokenizer.eos_token
                                else:
                                    tokenizer.add_special_tokens({'pad_token': '[PAD]'})
                            tokenizer.padding_side = 'right'

                            # Dataset
                            train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})
                            test_dataset = Dataset.from_dict({'text': test_texts, 'label': test_labels})

                            def preprocess_function(examples):
                                tokenized = tokenizer(
                                    examples['text'],
                                    truncation=True,
                                    max_length=max_length,
                                    padding=True
                                )
                                tokenized['labels'] = examples['label']
                                return tokenized

                            tokenized_train = train_dataset.map(preprocess_function, batched=True)
                            tokenized_test = test_dataset.map(preprocess_function, batched=True)
                            tokenized_train = tokenized_train.remove_columns(['text', 'label'])
                            tokenized_test = tokenized_test.remove_columns(['text', 'label'])

                            # Model
                            bnb_config = BitsAndBytesConfig(
                                load_in_4bit=True,
                                bnb_4bit_quant_type='nf4',
                                bnb_4bit_compute_dtype='float16',
                                bnb_4bit_use_double_quant=True
                            )
                            model = AutoModelForSequenceClassification.from_pretrained(
                                base_model_id,
                                num_labels=len(unique_labels),
                                device_map='auto',
                                quantization_config=bnb_config
                            )
                            model.config.use_cache = False
                            model.config.pad_token_id = tokenizer.pad_token_id

                            # PEFT
                            peft_config = LoraConfig(
                                lora_alpha=int(lora_alpha),
                                lora_dropout=lora_dropout,
                                r=int(lora_r),
                                bias='none',
                                task_type='SEQ_CLS',
                                target_modules=['k_proj','gate_proj','v_proj','up_proj','q_proj','o_proj','down_proj']
                            )
                            model = prepare_model_for_kbit_training(model)
                            model = get_peft_model(model, peft_config)

                            # SFTConfig ìƒì„± (Streamlit í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°˜ì˜)
                            sft_args = SFTConfig(
                                output_dir=os.path.join(output_dir, model_name),
                                learning_rate=learning_rate,
                                per_device_train_batch_size=batch_size,
                                per_device_eval_batch_size=batch_size,
                                gradient_accumulation_steps=2,
                                optim='paged_adamw_32bit',
                                lr_scheduler_type='cosine',
                                num_train_epochs=num_epochs,
                                warmup_steps=50,
                                logging_steps=10,
                                fp16=True,
                                gradient_checkpointing=True,
                                dataset_text_field='text',
                                max_length=max_length,
                                label_names=['labels']
                            )

                            data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

                            # Trainer
                            trainer = SFTTrainer(
                                model=model,
                                train_dataset=tokenized_train,
                                eval_dataset=tokenized_test,
                                processing_class=tokenizer,
                                args=sft_args,
                                data_collator=data_collator,
                                peft_config=peft_config
                            )

                            trainer.train()
                            trainer.save_model(os.path.join(output_dir, model_name))
                            tokenizer.save_pretrained(os.path.join(output_dir, model_name))

                            st.success(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ì €ì¥ ê²½ë¡œ: {os.path.join(output_dir, model_name)}")

                        except Exception as e:
                            st.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            st.exception(e)
        else:
            st.info("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ í•™ìŠµ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")


